{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kjcdGdmux4M"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Install all required packages\n",
        "!pip install -U pip\n",
        "!pip install biomed-multi-alignment[examples] tdc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7AG2_V_wdQ2"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1Bqcy-2238h"
      },
      "outputs": [],
      "source": [
        "# === MOUNT DRIVE ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# === IMPORTS ===\n",
        "import os, gc\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from mammal.model import Mammal\n",
        "from fuse.data.tokenizers.modular_tokenizer.op import ModularTokenizerOp\n",
        "from mammal.examples.dti_bindingdb_kd.task import DtiBindingdbKdTask\n",
        "\n",
        "# === DEVICE SETUP ===\n",
        "print(\"‚úÖ PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"üí° Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è GPU not available. Using CPU.\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === CONFIG ===\n",
        "input_path = \"/content/step2_filtered_lipinski.csv\"\n",
        "output_path = \"/content/drive/MyDrive/inference_results_partial.csv\"\n",
        "final_output_path = \"/content/drive/MyDrive/TeamYOURTEAMNAME.csv\"  # Change for final submission\n",
        "\n",
        "target_sequence = \"\"\"PEQPFIVLGQEEYGEHHSSIMHCRVDCSGRRVASLDVDGVIKVWSFNPIMQTKASSISKSPLLSLEWATKRDRLLLLGSGVGTVRLYDTEAKKNLCEININDNMPRILSLACSPNGASFVCSAAAPSLTSQVPGRLLLWDTKTMKQQLQFSLDPEPIAINCTAFNHNGNLLVTGAADGVIRLFDMQQHECAMSWRAHYGEVYSVEFSYDENTVYSIGEDGKFIQWNIHKSGLKVSEYSLPSDATGPFVLSGYSGYKQVQVPRGRLFAFDSEGNYMLTCSATGGVIYKLGGDEKVLESCLSLGGHRAPVVTVDWSTAMDCGTCLTASMDGKIKLTTLLAHKA\"\"\"\n",
        "norm_y_mean = 5.79384684128215\n",
        "norm_y_std = 1.33808027428196\n",
        "BATCH_SIZE = 3  # Safe for T4 or lower\n",
        "\n",
        "# === LOAD MODEL AND TOKENIZER ===\n",
        "model = Mammal.from_pretrained(\"ibm/biomed.omics.bl.sm.ma-ted-458m.dti_bindingdb_pkd\")\n",
        "model.eval().to(device)\n",
        "tokenizer_op = ModularTokenizerOp.from_pretrained(\"ibm/biomed.omics.bl.sm.ma-ted-458m.dti_bindingdb_pkd\")\n",
        "\n",
        "# === INPUT FILE LOADING AND RESUME SUPPORT ===\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "if os.path.exists(output_path):\n",
        "    existing_df = pd.read_csv(output_path)\n",
        "    done_ids = set(existing_df[\"RandomID\"])\n",
        "    print(f\"‚úÖ Resuming from {len(done_ids)} predictions.\")\n",
        "else:\n",
        "    existing_df = pd.DataFrame(columns=[\"RandomID\", \"Sel_50\", \"Score\"])\n",
        "    done_ids = set()\n",
        "\n",
        "df = df[~df[\"RandomID\"].isin(done_ids)].reset_index(drop=True)\n",
        "print(f\"üß™ Remaining to process: {len(df)} molecules\")\n",
        "all_batches = [df[i:i + BATCH_SIZE] for i in range(0, len(df), BATCH_SIZE)]\n",
        "\n",
        "# === INFERENCE LOOP ===\n",
        "for batch_df in tqdm(all_batches):\n",
        "    try:\n",
        "        samples, ids = [], []\n",
        "\n",
        "        for _, row in batch_df.iterrows():\n",
        "            try:\n",
        "                sample_dict = {\n",
        "                    \"target_seq\": target_sequence,\n",
        "                    \"drug_seq\": row[\"SMILES\"]\n",
        "                }\n",
        "                sample_dict = DtiBindingdbKdTask.data_preprocessing(\n",
        "                    sample_dict=sample_dict,\n",
        "                    tokenizer_op=tokenizer_op,\n",
        "                    target_sequence_key=\"target_seq\",\n",
        "                    drug_sequence_key=\"drug_seq\",\n",
        "                    norm_y_mean=None,\n",
        "                    norm_y_std=None,\n",
        "                    device=device\n",
        "                )\n",
        "                samples.append(sample_dict)\n",
        "                ids.append(row[\"RandomID\"])\n",
        "            except RuntimeError as e:\n",
        "                print(f\"‚ö†Ô∏è Skipping SMILES ({row['RandomID']}): {e}\")\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "        if not samples:\n",
        "            continue\n",
        "\n",
        "        # üîÅ Ensure tensors are moved to correct device (very important!)\n",
        "        for i, sample in enumerate(samples):\n",
        "            samples[i] = {k: v.to(device) if torch.is_tensor(v) else v for k, v in sample.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch_out = model.forward_encoder_only(samples)\n",
        "\n",
        "        batch_out = DtiBindingdbKdTask.process_model_output(\n",
        "            batch_out,\n",
        "            scalars_preds_processed_key=\"model.out.dti_bindingdb_kd\",\n",
        "            norm_y_mean=norm_y_mean,\n",
        "            norm_y_std=norm_y_std\n",
        "        )\n",
        "\n",
        "        scores = batch_out[\"model.out.dti_bindingdb_kd\"]\n",
        "        results_batch = pd.DataFrame({\n",
        "            \"RandomID\": ids,\n",
        "            \"Sel_50\": 0,\n",
        "            \"Score\": [s.cpu().item() for s in scores]\n",
        "        })\n",
        "\n",
        "        results_batch.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)\n",
        "        os.sync()  # Force disk sync\n",
        "\n",
        "        del samples, ids, sample_dict, batch_out, results_batch, scores\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        print(f\"üî• Batch error: {e}\")\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "# === FINAL STEP: Select Top 50 ===\n",
        "print(\"üéØ Selecting top 50 compounds...\")\n",
        "final_df = pd.read_csv(output_path)\n",
        "final_df = final_df.sort_values(by=\"Score\", ascending=False)\n",
        "final_df.loc[final_df.head(50).index, \"Sel_50\"] = 1\n",
        "final_df.to_csv(final_output_path, index=False)\n",
        "print(f\"‚úÖ Submission file saved to: {final_output_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}